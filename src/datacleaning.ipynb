{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA\n",
    "\n",
    "Load positive tweets into a raw text string to process words and into a data frame to preseve the mapping of words to messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('../data/train_pos.txt')\n",
    "raw_data = file.read()\n",
    "raw_text = pd.read_table('../data/train_pos.txt',header = None)\n",
    "positiveTweets = raw_text[0].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97902\n"
     ]
    }
   ],
   "source": [
    "num_of_tweets = positiveTweets.shape[0]\n",
    "print(num_of_tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING\n",
    "\n",
    "Clean the data by removing emoticons , hashtags along with their content , any form of digits and punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTweets(tweets):\n",
    "    \n",
    "    replace_emoticons = r'\\s(\\w+)\\s((?::|;|=)(?:-)?(?:\\)|D|P))'\n",
    "    noemotions_tweets = re.sub(replace_emoticons, 'happy', tweets)\n",
    "    remove_numbers = r'\\d+'\n",
    "    remove_punctuation = r\"[.,;'?():-_]\"\n",
    "    remove_hashtags = r\"#(\\w+)\"\n",
    "    remove_special_characters = '!|$|%'\n",
    "    combined_pattern = r'|'.join((remove_numbers,remove_punctuation,remove_hashtags,remove_special_characters))\n",
    "    cleaned_tweets = re.sub(combined_pattern,'',noemotions_tweets )\n",
    "    \n",
    "    return  cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeStopWords(tokens,StopWords):\n",
    "    \n",
    "    content = [w for w in tokens if w not in stopwords]\n",
    "    removeWhite = list(filter(lambda name: name.strip(), content))\n",
    "    return removeWhite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZATION\n",
    "\n",
    "Apply data cleaning methods to text then use tokenizer to create the vocabulary that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = cleanTweets(raw_data)\n",
    "tokens = nltk.word_tokenize(raw_data)\n",
    "words = [w.lower() for w in tokens]\n",
    "stopwords = stopwords.words('english')\n",
    "words_without_stopwords = removeStopWords(words,stopwords)\n",
    "vocab = sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44299\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '$', '&', \"''\", '*', '+', '-', '--', '-/', '-bitin', '-brookevalentine', '-chelsea', '-d', '-day-lecturebow', '-do', '-i', '-in', '-literally', '-lzocleaned', '-mobile', '-naked', '-nightblue', '-o-d-day', '-p', '-pop', '-tastic', '-tern', '-vacation', '-ver', '-|', '/', '`', '``', 'a', 'a-bomb', 'a-day', 'a-englands', 'a-go-go', 'a-j-a', 'a-level', 'a-levels', 'a-lister', 'a-okay', 'a-rod', 'a-ry', 'a-s', 'a-s-i-a', 'a-savage', 'aa', 'aaa', 'aaactually', 'aaages', 'aaah', 'aaahah', 'aaahahhlrfiunwerjfdns', 'aaahh', 'aaahhaaa', 'aaahhgggahshdjadjldlaldlglgls', 'aaahhh', 'aaahhww', 'aaahw', 'aaak', 'aaall', 'aaalll', 'aaand', 'aaanyone', 'aaard', 'aaaron', 'aaaw', 'aaawh', 'aaaww', 'aaawweee', 'aaawww', 'aaawwwh', 'aaawwwhhh', 'aacchhhooo', 'aah', 'aaha', 'aahah', 'aahaha', 'aahahah', 'aahahaha', 'aahahha', 'aahh', 'aahha', 'aahhh', 'aaiey', 'aaj', 'aaliya', 'aaliyah', 'aaliyahs', 'aalleeaa', 'aalll', 'aalways', 'aama', 'aameen', 'aamiin', 'aamras', 'aand', 'aanhin']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COUNT MATRIX\n",
    "\n",
    "find the count of the vocabulary contained in your tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<97902x44299 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1058920 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(vocabulary=vocab)\n",
    "cv.fit_transform(positiveTweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
